@article{wu2025amodal3r,
  title={Amodal3r: Amodal 3d reconstruction from occluded 2d images},
  author={Wu, Tianhao and Zheng, Chuanxia and Guan, Frank and Vedaldi, Andrea and Cham, Tat-Jen},
  journal={ICCV},
  year={2025}
}

@article{duan2024aha,
  title={Aha: A vision-language-model for detecting and reasoning over failures in robotic manipulation},
  author={Duan, Jiafei and Pumacay, Wilbert and Kumar, Nishanth and Wang, Yi Ru and Tian, Shulin and Yuan, Wentao and Krishna, Ranjay and Fox, Dieter and Mandlekar, Ajay and Guo, Yijie},
  journal={ICLR},
  year={2025}
}

@InProceedings{pmlr-v270-curtis25a,
  title = 	 {Trust the PRoC3S: Solving Long-Horizon Robotics Problems with LLMs and Constraint Satisfaction},
  author =       {Curtis, Aidan and Kumar, Nishanth and Cao, Jing and Lozano-P\'erez, Tom\'as and Kaelbling, Leslie Pack},
  booktitle = 	 {Proceedings of The 8th Conference on Robot Learning},
  pages = 	 {1362--1383},
  year = 	 {2025},
  editor = 	 {Agrawal, Pulkit and Kroemer, Oliver and Burgard, Wolfram},
  volume = 	 {270},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--09 Nov},
  publisher =    {PMLR},
  abstract = 	 {Recent developments in pretrained large language models (LLMs) applied to robotics have demonstrated their capacity for sequencing a set of discrete skills to achieve open-ended goals in simple robotic tasks. In this paper, we examine the topic of LLM planning for a set of *continuously parameterized* skills whose execution must avoid violations of a set of kinematic, geometric, and physical constraints. We prompt the LLM to output code for a function with open parameters, which, together with environmental constraints, can be viewed as a Continuous Constraint Satisfaction Problem (CCSP). This CCSP can be solved through sampling or optimization to find a skill sequence and continuous parameter settings that achieve the goal while avoiding constraint violations. Additionally, we consider cases where the LLM proposes unsatisfiable CCSPs, such as those that are kinematically infeasible, dynamically unstable, or lead to collisions, and re-prompt the LLM to form a new CCSP accordingly. Experiments across simulated and real-world domains demonstrate that our proposed strategy, \OursNoSpace, is capable of solving a wide range of complex manipulation tasks with realistic constraints much more efficiently and effectively than existing baselines.}
}

@inproceedings{wen2023bundlesdf,
  title={Bundlesdf: Neural 6-dof tracking and 3d reconstruction of unknown objects},
  author={Wen, Bowen and Tremblay, Jonathan and Blukis, Valts and Tyree, Stephen and M{\"u}ller, Thomas and Evans, Alex and Fox, Dieter and Kautz, Jan and Birchfield, Stan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={606--617},
  year={2023}
}

@inproceedings{pfrommer2021contactnets,
  title={Contactnets: Learning discontinuous contact dynamics with smooth, implicit representations},
  author={Pfrommer, Samuel and Halm, Mathew and Posa, Michael},
  booktitle={Conference on Robot Learning},
  pages={2279--2291},
  year={2021},
  organization={PMLR}
}

@article{d2021stein,
  title={On stein variational neural network ensembles},
  author={D'Angelo, Francesco and Fortuin, Vincent and Wenzel, Florian},
  journal={arXiv preprint arXiv:2106.10760},
  year={2021}
}

@inproceedings{pfrommer2021contactnets,
  title={Contactnets: Learning discontinuous contact dynamics with smooth, implicit representations},
  author={Pfrommer, Samuel and Halm, Mathew and Posa, Michael},
  booktitle={Conference on Robot Learning},
  pages={2279--2291},
  year={2021},
  organization={PMLR}
}


@article{wu2025foresight,
  title={From foresight to forethought: Vlm-in-the-loop policy steering via latent alignment},
  author={Wu, Yilin and Tian, Ran and Swamy, Gokul and Bajcsy, Andrea},
  journal={RSS},
  year={2025}
}

@article{ren2024grounded,
  title={Grounded sam: Assembling open-world models for diverse visual tasks},
  author={Ren, Tianhe and Liu, Shilong and Zeng, Ailing and Lin, Jing and Li, Kunchang and Cao, He and Chen, Jiayu and Huang, Xinyu and Chen, Yukang and Yan, Feng and others},
  journal={arXiv preprint arXiv:2401.14159},
  year={2024}
}

@article{zhao2024open,
  title={An open and comprehensive pipeline for unified object grounding and detection},
  author={Zhao, Xiangyu and Chen, Yicheng and Xu, Shilin and Li, Xiangtai and Wang, Xinjiang and Li, Yining and Huang, Haian},
  journal={arXiv preprint arXiv:2401.02361},
  year={2024}
}

@inproceedings{wen2024foundationpose,
  title={Foundationpose: Unified 6d pose estimation and tracking of novel objects},
  author={Wen, Bowen and Yang, Wei and Kautz, Jan and Birchfield, Stan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={17868--17879},
  year={2024}
}

@article{ravi2024sam,
  title={Sam 2: Segment anything in images and videos},
  author={Ravi, Nikhila and Gabeur, Valentin and Hu, Yuan-Ting and Hu, Ronghang and Ryali, Chaitanya and Ma, Tengyu and Khedr, Haitham and R{\"a}dle, Roman and Rolland, Chloe and Gustafson, Laura and others},
  journal={arXiv preprint arXiv:2408.00714},
  year={2024}
}

@inproceedings{simeonov2023shelving,
  title={Shelving, Stacking, Hanging: Relational Pose Diffusion for Multi-modal Rearrangement},
  author={Simeonov, Anthony and Goyal, Ankit and Manuelli, Lucas and Lin, Yen-Chen and Sarmiento, Alina and Garcia, Alberto Rodriguez and Agrawal, Pulkit and Fox, Dieter},
  booktitle={Conference on Robot Learning},
  pages={2030--2069},
  year={2023},
  organization={PMLR}
}
@article{wright2024robust,
  title={Robust Bayesian Scene Reconstruction by Leveraging Retrieval-Augmented Priors},
  author={Wright, Herbert and Zhi, Weiming and Johnson-Roberson, Matthew and Hermans, Tucker},
  journal={arXiv preprint arXiv:2411.19461},
  year={2024}
}
